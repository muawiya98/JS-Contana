{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8oupah-XC_Y4"},"outputs":[],"source":["# !pip install -q keras==2.8.0\n","# !pip install -q tensorflow==2.8.0"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"VVCYqVQsFX3H","executionInfo":{"status":"ok","timestamp":1686645809757,"user_tz":-180,"elapsed":4903,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, Conv1D, GlobalMaxPooling1D ,Conv2D ,GlobalMaxPooling2D,Flatten,Conv2DTranspose,Reshape\n","from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n","from keras.callbacks import ModelCheckpoint, EarlyStopping,Callback,CSVLogger\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential, load_model\n","from sklearn.tree import DecisionTreeClassifier\n","from keras.utils.vis_utils import plot_model\n","from sklearn.datasets import make_regression\n","from sklearn.metrics import accuracy_score\n","from warnings import filterwarnings\n","from collections import defaultdict\n","from scipy.special import softmax\n","from xgboost import XGBClassifier\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from keras import backend as K\n","from collections import deque\n","from typing import Callable\n","from keras import layers\n","import tensorflow as tf\n","from sklearn import svm\n","from typing import List\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import requests\n","import random\n","import pickle\n","import keras\n","import copy\n","import json\n","import sys\n","import os\n","import re\n","\n","sns.set(rc = {'figure.figsize':(22,12)}, style=\"whitegrid\")\n","filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aqPJLr6D0iu_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686645834557,"user_tz":-180,"elapsed":24414,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}},"outputId":"cc32a91d-4de1-4273-a852-2659a4a4a476"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MdVp6aXl0ogM","executionInfo":{"status":"ok","timestamp":1686645834558,"user_tz":-180,"elapsed":5,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["par_path = '/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Hiden'\n","def FSR_P():return '/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Featuer_selection_results'\n","def MINFO_P():return '/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Featuer_selection_results'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QI0W_ag-0D0U","executionInfo":{"status":"ok","timestamp":1686645841246,"user_tz":-180,"elapsed":589,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class GarbageCollectorCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        gc.collect()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"EMvpWwcD00vJ","executionInfo":{"status":"ok","timestamp":1686645842111,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def creat_callbacks():\n","  checkpoint = ModelCheckpoint(os.path.join(model_info_path,\"Dfs_weights.best.hdf5\"), monitor='val_loss', verbose=False, save_best_only=True, mode='min')\n","  history_logger = CSVLogger(os.path.join(model_info_path,'Dfs_history.csv'), separator=\",\", append=True)\n","  es = EarlyStopping(monitor='val_loss', patience=5)\n","  callbacks_list = [GarbageCollectorCallback(),checkpoint, es,history_logger]\n","  return callbacks_list"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"mrS6S3A_1OpI","executionInfo":{"status":"ok","timestamp":1686645842112,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def create_network(shape):\n","    \"\"\"\n","    _INPUT (down) IF WE WANT TO CREAT MODEL WITHOUT FIRST LSTM LAYER  (shape) IF THE PREVIOS PAREMETER IS TRUE WE NEED DIFINE THE SHAPE FOR INPUT LAYER\n","    _OUTPUT THE MODEL\n","    \"\"\"\n","    model = Sequential()\n","    model.add(layers.InputLayer(input_shape=shape))\n","    # TextCNN with 4 conv layers\n","    model.add(Conv1D(128, 7, activation='tanh', input_shape=(None, 32)))\n","    model.add(Conv1D(128, 15, activation='tanh'))\n","    model.add(Conv1D(128, 25, activation='tanh'))\n","    model.add(Conv1D(128, 35, activation='tanh'))\n","    model.add(GlobalMaxPooling1D())\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","    # model.load_weights(os.path.join(model_info_path,\"Dfs_weights.best.hdf5\"))\n","    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","    # model.summary()\n","    plot_model(model, to_file=os.path.join(model_info_path,'text_cnn_model.png'), show_shapes=True, show_layer_names=True)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"8Pd-RhXiqz7f"},"source":["# 1. Policy Function & DQN Architicture\n","* 1- epsilon greedy implementaion for make action\n","* 2- DQN model and compile"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OwP_3Tj_FXz0","executionInfo":{"status":"ok","timestamp":1686645843767,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def epsilon_greedy(expected_reward, epsilon=0.97) -> int:\n","    \"\"\"\n","    expected_reward: list of expected rewards for each possible action\n","    epsilon: .\n","    \"\"\"\n","    if np.random.rand() <= epsilon:\n","        return np.random.choice(list(range(len(expected_reward))))\n","    else:\n","        return np.argmax(expected_reward)\n","\n","PolicyFunction  = Callable[[np.ndarray, float], int]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"FCL570_PFXxS","executionInfo":{"status":"ok","timestamp":1686645843768,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["LEARNING_RATE = 0.001\n","\n","def create_model(input_dim):\n","    K.clear_session()\n","    model = keras.models.Sequential()\n","    model.add(keras.layers.Input(shape=(input_dim,)))\n","    model.add(keras.layers.Dense(32, kernel_initializer='he_uniform', activation='relu'))\n","    model.add(keras.layers.Dense(16, kernel_initializer='he_uniform', activation='relu'))\n","    model.add(keras.layers.Dense(2))\n","    model.compile(loss='mse', optimizer='adam')\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"2Y2BCuRD7rZE"},"source":["## 2. Agents Implementaion\n","\n","* Agents class will be the parent of 4 types of agents listed as follow:\n","    * 1- Softmax version (distrbute the total reward between agents using softmax function)\n","    * 2- Average version (distrbute the total reward between agents using average function)\n","    * 1- regression version (calcualte the contrbution of each agent using regression model)\n","    * 1- Single Agent version (only one agent at a time can make action and get the total reawrd as a result)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3nrHdg77tDAF","executionInfo":{"status":"ok","timestamp":1686645844835,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class Agents:\n","    # class variable\n","    agent_count = 0\n","    def __init__(self, evaluation_network, buffer_size: int = 800):\n","        self.evaluation_network = evaluation_network\n","        self.target_network = copy.deepcopy(self.evaluation_network)\n","        self.buffer_size = buffer_size\n","        self.fitted = False\n","        self.agent_id = Agents.agent_count\n","        Agents.agent_count += 1\n","        # reply buffer is a list of tuples each tuples contains the following\n","        # (St, At, St+1, Rt+1)\n","        # (Current state, Action was made, New state, Reward)\n","        self.reply_buffer = deque(maxlen=self.buffer_size)\n","        self.contrbution = np.random.rand()\n","    def make_action(self, curr_state: np.ndarray, policy_function: PolicyFunction, epsilon) -> int:\n","        # q_values represents the expected rewards for each possible action\n","        if self.fitted:\n","            q_values = self.evaluation_network.predict(curr_state.reshape(-1, 100)) # Agents.agent_count\n","            action = policy_function(q_values, epsilon)\n","        else:\n","            action = policy_function([0, 1], 1)\n","        return action\n","    def update_target_network(self):\n","        self.target_network = copy.deepcopy(self.evaluation_network)\n","        return"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"XQSWchnH7oA8","executionInfo":{"status":"ok","timestamp":1686645845219,"user_tz":-180,"elapsed":386,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class AgentsSoftmax(Agents):\n","    def __init__(self, evaluation_network, buffer_size=800):\n","        super().__init__(evaluation_network, buffer_size)\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        # select random batch from the reply buffer\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        # inintilize some lists to store transition information\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        # from each transition extract its values\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        # X_train will be the states from\n","        X_train = np.array(Q1)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1))\n","        Q2 = self.target_network.predict(np.array(Q2))\n","\n","        # update expected rewards using biliman equation\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        # calculate the change frequency of the agent decision to use it as its contrbution in get total reward\n","        change_frequency = 0\n","        for state, next_state, reward, next_reward in zip(X_train[:-1], X_train[1:], rewards[: -1], rewards[1:]):\n","            # print(state, next_state, reward, next_reward)\n","            for id in range(len(state)):\n","              if state[id] != next_state[id]: #) == 1: np.abs(\n","                  self.contrbution += np.abs(reward - next_reward)\n","                  change_frequency += 1\n","        self.contrbution /= change_frequency\n","        # train the DQN evaluation network.\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vNDAHxc5tDAH","executionInfo":{"status":"ok","timestamp":1686645845220,"user_tz":-180,"elapsed":4,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class AgentsRegression(Agents):\n","    def __init__(self, evaluation_network, buffer_size=800):\n","        super().__init__(evaluation_network, buffer_size)\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        # select random batch from the reply buffer\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        # inintilize some lists to store transition information\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        # from each transition extract its values\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        # X_train will be the states from\n","\n","        X_train = np.array(Q1)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1))\n","        Q2 = self.target_network.predict(np.array(Q2))\n","\n","        # update expected rewards using biliman equation\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        # train the DQN evaluation network.\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"j8qArfCotDAI","executionInfo":{"status":"ok","timestamp":1686645845220,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class AgentsAverage(Agents):\n","    def __init__(self, evaluation_network, buffer_size=800):\n","        super().__init__(evaluation_network, buffer_size)\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        # select random batch from the reply buffer\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        # inintilize some lists to store transition information\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        # from each transition extract its values\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        # X_train will be the states from\n","\n","        X_train = np.array(Q1)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1))\n","        Q2 = self.target_network.predict(np.array(Q2))\n","\n","        # update expected rewards using biliman equation\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        WINDOW_SIZE = 4\n","        X_train_ = np.zeros((X_train.shape[0] // WINDOW_SIZE, X_train.shape[1]))\n","        y_train_ = []\n","        j = 0\n","        for i in range(0, batch_size, WINDOW_SIZE):\n","            window_of_states = X_train[i: i + WINDOW_SIZE].sum(axis=0) / WINDOW_SIZE\n","            window_of_rewards = sum(rewards[i: i + WINDOW_SIZE])\n","            r = window_of_rewards * window_of_states[self.agent_id]\n","             # Rounding state\n","            X_train_[j, :] = np.around(window_of_states)\n","            if window_of_states[self.agent_id] == 0:\n","                if window_of_rewards > 0.6:\n","                    r = window_of_rewards\n","                else:\n","                    r = window_of_rewards / WINDOW_SIZE\n","            y_train_.append(r)\n","            j += 1\n","\n","        X_train = X_train_\n","        y_train = np.array(y_train_)\n","        # train the DQN evaluation network.\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"wKt-pHVftDAI","executionInfo":{"status":"ok","timestamp":1686645845220,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["class AgentsSingle(Agents):\n","    def __init__(self, evaluation_network, buffer_size=800):\n","        super().__init__(evaluation_network, buffer_size)\n","    def update_evaluation_network(self, batch_size=32, epochs=5, discount_factor=0.995):\n","        # select random batch from the reply buffer\n","        batch = random.sample(self.reply_buffer, batch_size)\n","        # inintilize some lists to store transition information\n","        Q1, actions, Q2, rewards = [], [], [], []\n","        # from each transition extract its values\n","        for transition in batch:\n","            Q1.append(transition[0])\n","            actions.append(transition[1])\n","            Q2.append(transition[2])\n","            rewards.append(transition[3])\n","        # X_train will be the states from\n","\n","        X_train = np.array(Q1)\n","        expected_reward = self.evaluation_network.predict(np.array(Q1))\n","        Q2 = self.target_network.predict(np.array(Q2))\n","\n","        # update expected rewards using biliman equation\n","        for i, act in enumerate(actions[:-1]):\n","            expected_reward[i, act] = rewards[i] + (discount_factor * np.argmax(Q2[i]))\n","        y_train = expected_reward.copy()\n","        # train the DQN evaluation network.\n","        # print\n","        self.evaluation_network.fit(X_train, y_train, epochs=epochs, verbose=0)\n","        self.fitted = True\n","        return"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"YeWkujk7kM0w","executionInfo":{"status":"ok","timestamp":1686645845221,"user_tz":-180,"elapsed":4,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def _replaceitem(x):\n","    if type(x) is list:\n","        if x[0]<0.5:\n","            return 0.0\n","    else:\n","        x = float(x)\n","        if x<0.5:\n","            return 0.0\n","    return 1.0"]},{"cell_type":"markdown","metadata":{"id":"FrTADQm3tDAJ"},"source":["# 3. Reward Calculation Method\n","* 1- get accuracy of selected feature using logistic regression model\n","* 2- claculate the reward with reward_strategy function using accuracy from last step."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"eCWQYFgdtDAJ","executionInfo":{"status":"ok","timestamp":1686645845644,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["# test set percentage\n","TESTSIZE=0.2\n","def get_reward(X:np.numarray, Y:np.numarray, subset_features:list, y_label:str):\n","    global TESTSIZE\n","    # index of selected features\n","    subset_features = np.where(np.array(subset_features) == 1)[0]\n","    if subset_features.shape[0] == 0:return 0\n","    # train test split\n","    X, Y = X[:,:,subset_features.tolist()], Y\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=TESTSIZE)\n","\n","\n","    # classification and model evaluation\n","    model = create_network(shape=X_train[0].shape)\n","    model.fit(X_train, y_train,epochs=10, validation_split=0.20,verbose=0)\n","    y_pred = model.predict(X_test)\n","    y_test = list(map(_replaceitem, y_test))\n","    y_pred = list(map(_replaceitem, y_pred))\n","    acc = accuracy_score(y_test, y_pred)\n","    return acc"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BbwuY9l_tDAK","executionInfo":{"status":"ok","timestamp":1686645848291,"user_tz":-180,"elapsed":4,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def reward_strategy(time_step: int, accuracy: float, accuracy_history: list, subset_features: list, error_rate: float,beta: float = 0.99):\n","    if sum(subset_features) == len(subset_features):\n","        return -5\n","    elif accuracy > max(accuracy_history):\n","        return 0.5\n","    elif accuracy < max(accuracy_history):\n","        return -0.1\n","    else:\n","        return -1 * (beta * error_rate + ((1 - beta) * (sum(subset_features) / len(subset_features))))"]},{"cell_type":"markdown","metadata":{"id":"Iy26h3kVtDAK"},"source":["# 4. Some helper function\n","* 1- Object to store all information about the result like dataset name, accuracy, precision and etc...\n","* 2- Telegram api to send the result to a chat room\n","* 3- Send result to the chat room"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"KvIWrubNBU4Z","executionInfo":{"status":"ok","timestamp":1686645849006,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["import pickle\n","\n","class Results:\n","    def __init__(self, method_name, dataset_name, chunk_id, feature_space):\n","        self.dataset_name = dataset_name\n","        self.method_name = method_name\n","        self.chunk_id = chunk_id\n","        self.feature_space = feature_space\n","        self.feature_space_size = len(feature_space)\n","        self.result_information = {}\n","\n","    def set_chunk_id(self, chunk_id: int):\n","        self.chunk_id = chunk_id\n","\n","    def set_feature_space(self, feature_space: list):\n","        self.feature_space = feature_space\n","        self.feature_space_size = len(feature_space)\n","\n","    def add_result(self, model_type:str, result:dict):\n","        self.result_information[model_type] = result\n","\n","    def save(self, path='feature_selection_results'):\n","        dataset_name = path+\"_\"+self.dataset_name.split('/')[-1].split('.')[0]\n","        file_name = self.method_name + '_' + dataset_name + '_' + '{}'.format(self.chunk_id) + '.pkl'\n","        PATH = os.path.join(feature_selection_results_path, self.method_name)\n","        with open(os.path.join(PATH, file_name), 'wb') as file_:\n","            pickle.dump(self, file_, pickle.HIGHEST_PROTOCOL)\n","        return"]},{"cell_type":"markdown","metadata":{"id":"WhBpgSFaSn9X"},"source":["# 5. Feature Selection Main Algorithm\n","* For each type of agents we need a specific feature selection algorithm with little difference between them.\n","* Evaluation function using different machine learning model based on selected feature\n","* Result Visulization"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"n3koWaXEtDAL","executionInfo":{"status":"ok","timestamp":1686645851767,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def softmax_distrbution(agents):\n","    contrbutions = []\n","    for agent in agents:\n","      contrbutions.append(agent.contrbution)\n","    return softmax(contrbutions)\n","\n","def random_forest_distrbution(X,Y, num_of_samples=10000):\n","    TX = []\n","    Ty = []\n","    num_of_agents = X.shape[2]\n","    for i in range(num_of_samples):\n","        features_space = np.random.choice([0, 1], size=(num_of_agents,)).tolist()\n","        accuracy = get_reward(X,Y, features_space, 'target')\n","        TX.append(features_space)\n","        Ty.append(accuracy)\n","    TX = np.array(TX)\n","    Ty = np.array(Ty)\n","    rf = RandomForestRegressor(n_estimators=15)\n","    rf.fit(TX, Ty)\n","    return rf.feature_importances_.tolist()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"9A0KUfP6Sogv","executionInfo":{"status":"ok","timestamp":1686645856839,"user_tz":-180,"elapsed":1,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def feature_selection(algo_type:str, agents: list, X: np.numarray,Y: np.numarray, y_label: str, NUM_OF_FEATURES, NUM_OF_AGENT, eposide=100):\n","    \"\"\"\n","    \"\"\"\n","    epsilon = 0.01\n","    features_space = [] # Need_fix\n","    contrbutions = []\n","    if algo_type == 'random_forest':\n","        contrbutions = random_forest_distrbution(X,Y)\n","    elif algo_type in ['single_agent', 'average']:\n","        contrbutions = [1] * NUM_OF_FEATURES\n","    for i in tqdm(range(eposide)):\n","        # define the initial space\n","        features_space = np.random.choice([0, 1], size=(NUM_OF_FEATURES,)).tolist() # Need_fix\n","        # rewards history\n","        rewards = [0]\n","        # get action of each agent to create new feature space\n","        next_feature_space = [] # Need_fix\n","        # contrbution of each agent\n","        if algo_type == 'softmax':\n","            contrbutions = softmax_distrbution(agents)\n","        for t in range(0, NUM_OF_AGENT):\n","            # for i in range(10):\n","            action = agents[t].make_action(np.array(features_space.copy()), epsilon_greedy, epsilon)\n","            next_feature_space.append(action) # Need_fix\n","            if algo_type == 'single_agent':\n","                features_space[t] = action # Need_fix\n","        # calculate the total accuracy of new state (new feature space) and distrbute it using softmax\n","        # 1- get the accuracy using machine learning model trained in the current subset feature\n","        reward_as_accuracy = get_reward(X,Y, next_feature_space, y_label)\n","        # 2- using the reward strategy map the accuracy value (reward_as_accuracy) to new reward value (reward_at_time_t)\n","        reward_at_time_t = reward_strategy(t, reward_as_accuracy, rewards, next_feature_space, 1 - reward_as_accuracy)\n","        # add the accuray of machine learning model to rewards list to use it in the mapping reward strategy.\n","        rewards.append(reward_as_accuracy)\n","        # total reward = reward after mapping\n","        total_reward = reward_at_time_t\n","        # add state and actions to agent buffer reply and the reward which equals to contrbution of the agent*total reward\n","        transition = []\n","        for t in range(0, NUM_OF_AGENT):\n","          # for i in range(10):\n","          transition.clear()\n","          # add current state (current feature space)\n","          feature_space_copy = features_space.copy()\n","          transition.append(feature_space_copy) # Need_fix\n","          # add agent's action to the transition\n","          action = next_feature_space[t]\n","          transition.append(action)\n","          # add new state (new feature space) into transition\n","          transition.append(next_feature_space) # Need_fix\n","          # add distrbuted reward to the transition\n","          transition.append(total_reward * contrbutions[t])\n","          # add the transition to reply buffer\n","          agents[t].reply_buffer.append(transition) # Need_fix\n","          if len(agents[t].reply_buffer) > 32 and i % 32 == 0:\n","              agents[t].update_evaluation_network()\n","        if i % 64 == 0:\n","            for agent in agents:\n","                if agent.fitted:\n","                    agent.update_target_network()\n","        epsilon = 0.97 * epsilon\n","    return next_feature_space"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3fqoHDcVfuTA","executionInfo":{"status":"ok","timestamp":1686645857373,"user_tz":-180,"elapsed":1,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["sns.set(rc={'figure.figsize':(15,12)})\n","\n","def print_result(y_pred, y_test , title ,color):\n","\n","    if len(y_test) < len(y_pred):\n","        y_pred = y_pred[: len(y_test)]\n","    elif len(y_test) > len(y_pred):\n","        y_test = y_test[: len(y_pred)]\n","\n","\n","    accuracy = accuracy_score(y_pred, y_test)\n","    classification_rep = classification_report(y_test, y_pred)\n","    con_matrix = confusion_matrix(y_test, y_pred)\n","\n","\n","    if len(con_matrix)==1:\n","        if len(con_matrix[0])==1:\n","            con_matrix = list(con_matrix)\n","            con_matrix[0] = list(con_matrix[0])\n","            con_matrix[0].append(0)\n","            con_matrix = np.array([con_matrix[0],[0,0]])\n","\n","    # ploting confustion matrix\n","    plt.figure(figsize=(25,15))\n","    plt.subplot(2,1,1)\n","\n","    T1 = y_test.count(0) if y_test.count(0)!=0 else 1\n","    T2 = y_test.count(1) if y_test.count(1)!=0 else 1\n","\n","    group_counts = con_matrix\n","    group_percentages = np.round(con_matrix / np.array([[T1 , T1],[T2 , T2]]),3)\n","\n","    t = 0.5\n","    plt.text(x=0.0 , y = 2.6, s =  \"confusion_matrix :\",fontsize=15)\n","    plt.text(x=0.0 , y = 3.3-t, s =  \"Zero \",fontsize=15)\n","    plt.text(x=0.0 , y = 3.4-t, s =  \"One  \",fontsize=15)\n","    plt.text(x=0.3 , y = 3.2-t, s =  \"Zero\",fontsize=15)\n","    plt.text(x=0.6 , y = 3.2-t, s =  \"One\",fontsize=15)\n","    plt.text(x=0.3 , y = 3.3-t, s =  \"{}\".format(con_matrix[0][0]),fontsize=15)\n","    plt.text(x=0.6 , y = 3.3-t, s =  \"{}\".format(con_matrix[0][1]),fontsize=15)\n","    plt.text(x=0.3 , y = 3.4-t, s =  \"{}\".format(con_matrix[1][0]),fontsize=15)\n","    plt.text(x=0.6 , y = 3.4-t, s =  \"{}\".format(con_matrix[1][1]),fontsize=15)\n","\n","    sns.heatmap(group_percentages,xticklabels=['Zero', 'One'], yticklabels=['Zero', 'One'], annot=True, annot_kws={\"size\": 16},fmt='g', cmap=color)\n","    plt.title(title ,  fontsize = 18)\n","    plt.text(x =0,y = 2.3 , s = \"accuracy  score on test : {}\".format(accuracy),fontsize=15)\n","    plt.text(x=0 , y = 3.9, s =  \"classification_report :\\n {}\".format(classification_rep),fontsize=15)\n","\n","    plt.xlabel(\"Predicted value\")\n","    plt.ylabel(\"Real value\")\n","\n","    plt.savefig(os.path.join(os.path.join(feature_selection_results_path,'Image'),\"{} .png\".format(title)))\n","    print(os.path.join(os.path.join(feature_selection_results_path,'Image'),\"{} .png\".format(title)))\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"IwXIOwYgtDAM","executionInfo":{"status":"ok","timestamp":1686645865562,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def model_evaluation(model,method_name, dataset_name, X_train,y_train,X_test,y_test, selected_features, target_column, chunk_id):\n","    subset_features = np.where(np.array(selected_features) == 1)[0]\n","    if subset_features.shape[0] == 0:return 0\n","    for i,x in enumerate(X_train):\n","      for j in range(x.shape[1]):\n","        x[:,j] = x[:,j]*selected_features[j]\n","      X_train[i] = x\n","\n","    for i,x in enumerate(X_test):\n","      for j in range(x.shape[1]):\n","        x[:,j] = x[:,j]*selected_features[j]\n","      X_test[i] = x\n","    model.fit(X_train, y_train,epochs=10, validation_split=0.20,verbose=0)\n","    # model.fit(X_train, y_train,epochs=10, validation_split=0.20,verbose=0,batch_size=100,callbacks=callbacks_list)\n","    model.save(os.path.join(model_info_path,\"model_with_dfs.h5\"))\n","    y_pred = model.predict(X_test)\n","    y_test = list(map(_replaceitem, y_test))\n","    y_pred = list(map(_replaceitem, y_pred))\n","\n","    # model.save_weights(os.path.join(model_info_path,'Model_Weights_for_chunk_'+str(chunk_id)))\n","    save_object(y_pred, \"y_pred_aftrer_fetuer_selection_chunk_\"+str(chunk_id),path=feature_selection_results_path)\n","    acc, p, r, f1, auc = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred)\n","    print_result(y_pred, y_test , \"chunk numer_\"+str(chunk_id) ,'Oranges')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"BXpJzhPQtDAM","executionInfo":{"status":"ok","timestamp":1686645866861,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def main(x_train_filenames, algorithm_type,num=4,is_ceated=True):\n","    # is_ceated = False #True\n","    for i,f_name in enumerate(x_train_filenames):\n","        if is_ceated and  i < num:\n","          continue\n","        chunk_id = i\n","        try :\n","          X_train = load_object(\"X_train_hiden_for_chunk_\"+str(i),par_path)\n","          Y_train = load_object(\"y_train_hiden_for_chunk_\"+str(i),par_path).to_numpy()\n","          X_test = load_object(\"X_test_hiden_for_chunk_\"+str(i),par_path)\n","          Y_test = load_object(\"y_test_hiden_for_chunk_\"+str(i),par_path).to_numpy()\n","        except :\n","          break\n","        if not is_ceated:\n","          model = create_network(shape=X_train[0].shape)\n","          is_ceated = True\n","        else:\n","          model = load_model(os.path.join(model_info_path,\"model_with_dfs.h5\"))\n","        number_of_samples = X_train.shape[0]\n","        agents = []\n","        Agents.agent_count = 0\n","        NUM_OF_FEATURES = X_train.shape[2]\n","        NUM_OF_AGENT = X_train.shape[2]\n","\n","        for i in range(NUM_OF_AGENT):\n","            if algorithm_type == 'softmax':\n","                agents.append(AgentsSoftmax(create_model(NUM_OF_FEATURES)))\n","            elif algorithm_type == 'average':\n","                agents.append(AgentsAverage(create_model(NUM_OF_FEATURES)))\n","            elif algorithm_type == 'single_agent':\n","                agents.append(AgentsSingle(create_model(NUM_OF_FEATURES)))\n","            elif algorithm_type == 'random_forest':\n","                agents.append(AgentsRegression(create_model(NUM_OF_FEATURES)))\n","        result = feature_selection(algorithm_type, agents,  X_train,Y_train, 'target',NUM_OF_FEATURES,NUM_OF_AGENT)\n","        save_object(result, \"results_of_\"+algorithm_type+\"_\"+str(chunk_id),path=feature_selection_results_path)\n","        model_evaluation(model,algorithm_type, f_name, X_train,Y_train,X_test,Y_test, result, 'target', chunk_id)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4Bvd3mv9tDAM","executionInfo":{"status":"ok","timestamp":1686645870024,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def save_object(obj, filename,path):\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'wb') as outp:\n","        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n","    outp.close()\n","def load_object(filename,path):\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'rb') as outp:\n","        loaded_object = pickle.load(outp)\n","    outp.close()\n","    return loaded_object"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"PrE1mqsSDFsh","executionInfo":{"status":"ok","timestamp":1686645870024,"user_tz":-180,"elapsed":1,"user":{"displayName":"Muawiya Al danaf","userId":"16999440410141197833"}}},"outputs":[],"source":["def convert_hiden_stat_to_csv(hiden):\n","  dfs = []\n","  for i in range(hiden.shape[0]):\n","    df = pd.DataFrame()\n","    for j in range(hiden[i].shape[1]):\n","      df[j] = [hiden[i][:,j]]\n","    dfs.append(df)\n","  return pd.concat(dfs,ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAh821FUtDAM"},"outputs":[],"source":["filenames = os.listdir(par_path)[::-1]\n","x_train_filenames = [i[:-4] for i in filenames if i[:7]=='X_train']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xGRWVT_tDAN","scrolled":true},"outputs":[],"source":["algo = 'softmax'\n","print(\"=============================== \"+algo+\" ===============================\")\n","feature_selection_results_path = os.path.join(FSR_P(),algo)\n","model_info_path = os.path.join(os.path.join(MINFO_P(),algo),\"Model info\")\n","callbacks_list = creat_callbacks()\n","main(x_train_filenames,algo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATDE0c7LuU7L"},"outputs":[],"source":["algo = 'average'\n","print(\"=============================== \"+algo+\" ===============================\")\n","feature_selection_results_path = os.path.join(FSR_P(),algo)\n","model_info_path = os.path.join(os.path.join(MINFO_P(),algo),\"Model info\")\n","callbacks_list = creat_callbacks()\n","main(x_train_filenames,algo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Hdg7WYbuVDM"},"outputs":[],"source":["algo = 'single_agent'\n","print(\"=============================== \"+algo+\" ===============================\")\n","feature_selection_results_path = os.path.join(FSR_P(),algo)\n","model_info_path = os.path.join(os.path.join(MINFO_P(),algo),\"Model info\")\n","callbacks_list = creat_callbacks()\n","main(x_train_filenames,algo)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDFCJ65suVNZ"},"outputs":[],"source":["# algo = 'random_forest'\n","# print(\"=============================== \"+algo+\" ===============================\")\n","# feature_selection_results_path = os.path.join(FSR_P(),algo)\n","# model_info_path = os.path.join(os.path.join(MINFO_P(),algo),\"Model info\")\n","# callbacks_list = creat_callbacks()\n","# main(x_train_filenames,algo)"]},{"cell_type":"code","source":[],"metadata":{"id":"xvmic0S7zEIx"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}