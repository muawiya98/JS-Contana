{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QZ2ymXUqWOeQ"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report, confusion_matrix\n","from keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, Conv1D, GlobalMaxPooling1D\n","from sklearn.metrics import silhouette_score,calinski_harabasz_score,davies_bouldin_score\n","from keras.callbacks import ModelCheckpoint, EarlyStopping,Callback,CSVLogger\n","from keras.models import Sequential, load_model,Model , clone_model\n","from sklearn.cluster import KMeans,DBSCAN,AgglomerativeClustering\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Activation, Dense, Reshape, Input\n","from keras.preprocessing.text import Tokenizer\n","from keras.losses import BinaryCrossentropy\n","from keras.backend import clear_session\n","from keras.initializers import Constant\n","from threading import current_thread\n","from keras.utils import plot_model\n","from sklearn.utils import shuffle\n","from keras.optimizers import Adam\n","from keras.utils import Sequence\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import tqdm\n","from keras import backend as K\n","from numpy.linalg import norm\n","from functools import partial\n","from random import uniform\n","from numpy import asarray\n","from copy import deepcopy\n","import concurrent.futures\n","from keras import layers\n","import matplotlib as mpl\n","from keras import Model\n","from numpy import save\n","from numpy import load\n","import seaborn as sns\n","# import esprima as esp\n","from time import time\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import tempfile\n","import logging\n","import urllib\n","import random\n","import pickle\n","import pydot\n","import torch\n","import math\n","import html\n","import nltk\n","import os\n","import re\n","import gc\n","warnings.filterwarnings(\"ignore\")\n","np.random.seed(123)\n","plt.style.use('ggplot')\n","# mpl.rcParams['figure.figsize'] = (12, 10)\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxgWX6jZGVC7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ku-SWpUoGVC7"},"outputs":[],"source":["par_path = \"/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Hiden\"\n","model_info_path = \"/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Results_TabuSearch3/Model info\"\n","results_path = \"/content/drive/MyDrive/Colab Notebooks/Muawiya/Js_Contana/On JavaScript File/Results_TabuSearch3\""]},{"cell_type":"code","source":["# par_path = \"/content/drive/MyDrive/Colab Notebooks/Js_Contana/On JavaScript File/Hiden\"\n","# model_info_path = \"/content/drive/MyDrive/Colab Notebooks/Js_Contana/On JavaScript File/Results_TabuSearch4/Model info\"\n","# results_path = \"/content/drive/MyDrive/Colab Notebooks/Js_Contana/On JavaScript File/Results_TabuSearch4\""],"metadata":{"id":"HLCDZ35-yiuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xKcTOwH2GVC8"},"outputs":[],"source":["class GarbageCollectorCallback(Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PFL3dqr-HwsW"},"outputs":[],"source":["def _replaceitem(x):\n","    if type(x) is list:\n","        if x[0]<0.5:return 0.0\n","    else:\n","        x=float(x)\n","        if x<0.5:return 0.0\n","    return 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hg_OhoRtGVC-"},"outputs":[],"source":["def save_object(obj, filename,path):\n","    \"\"\"\n","    _ INPUT (obj) THE OBJECT WE NEED SAVW IT (filename) THE NAME OF OBJECT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'wb') as outp:\n","        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n","    outp.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8sQUojTGVC_"},"outputs":[],"source":["def load_object(filename,path):\n","    \"\"\"\n","    _ INPUT THE NAME OF OBJECT WE NEED LOAD IT\n","    \"\"\"\n","    filename = os.path.join(path,filename)\n","    with open(filename+\".pkl\", 'rb') as outp:\n","        loaded_object = pickle.load(outp)\n","    outp.close()\n","    return loaded_object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0wZJWnTGVDB"},"outputs":[],"source":["def create_model(shape=None,without_first_layer=False,i=0):\n","    \"\"\"\n","    _INPUT (without_first_layer) IF WE WANT TO CREAT MODEL WITHOUT FIRST LSTM LAYER (shape) IF THE PREVIOS PAREMETER IS TRUE WE NEED DIFINE THE SHAPE FOR INPUT LAYER\n","    _OUTPUT THE MODEL\n","    \"\"\"\n","    clear_session()\n","    model = Sequential()\n","    name_model = 'tabu_search_model_'+str(i)+'_.best.hdf5'\n","    model.add(layers.InputLayer(input_shape=shape))\n","    # TextCNN with 4 conv layers\n","    model.add(Conv1D(128, 7, activation='tanh', input_shape=(None, 32)))\n","    model.add(Conv1D(128, 15, activation='tanh'))\n","    model.add(Conv1D(128, 25, activation='tanh'))\n","    model.add(Conv1D(128, 35, activation='tanh'))\n","    model.add(GlobalMaxPooling1D())\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","    # model.load_weights(os.path.join(model_info_path,name_model))\n","    plot_model(model, to_file=os.path.join(model_info_path,name_model[:-10]+'.png'), show_shapes=True, show_layer_names=True)\n","    # plot_model(model, to_file=os.path.join(model_info_path,name_model[:-10]+'.svg'), show_shapes=True, show_layer_names=True)\n","\n","    # model.summary()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXHC0IBRMdEj"},"outputs":[],"source":["def plot_finall_results(Best_F1_test,Best_Ac_test,Best_F1_train,Best_Ac_train,F1_test,Ac_test,F1_train,Ac_train,method_name,step=1):\n","  title = '2TS-DFS method Vs '+method_name\n","  fig, (ax1, ax2) = plt.subplots(1, 2, layout='constrained', figsize=(15, 4))\n","\n","  fig.suptitle(title)\n","\n","  ax1.plot([i for i, x in enumerate(Best_F1_test) if i % step == 0],[x for i, x in enumerate(Best_F1_test) if i % step == 0], color=\"red\",label=\"F1_Score_test\")\n","  ax1.plot([i for i, x in enumerate(Best_Ac_test) if i % step == 0],[x for i, x in enumerate(Best_Ac_test) if i % step == 0], color=\"blue\",label=\"Accurce_test\")\n","  ax1.plot([i for i, x in enumerate(Best_F1_train) if i % step == 0],[x for i, x in enumerate(Best_F1_train) if i % step == 0], color=\"yellow\",label=\"F1_Score_train\")\n","  ax1.plot([i for i, x in enumerate(Best_Ac_train) if i % step == 0],[x for i, x in enumerate(Best_Ac_train) if i % step == 0], color=\"green\",label=\"Accurce_train\")\n","\n","  ax1.legend(loc=\"best\")\n","  ax1.set_xlabel('Chunk')\n","  ax1.set_ylabel('Results per Chunk')\n","\n","  ax2.plot([i for i, x in enumerate(F1_test) if i % step == 0],[x for i, x in enumerate(F1_test) if i % step == 0], color=\"red\",label=\"F1_Score_test\")\n","  ax2.plot([i for i, x in enumerate(Ac_test) if i % step == 0],[x for i, x in enumerate(Ac_test) if i % step == 0], color=\"blue\",label=\"Accurce_test\")\n","  ax2.plot([i for i, x in enumerate(F1_train) if i % step == 0],[x for i, x in enumerate(F1_train) if i % step == 0], color=\"yellow\",label=\"F1_Score_train\")\n","  ax2.plot([i for i, x in enumerate(Ac_train) if i % step == 0],[x for i, x in enumerate(Ac_train) if i % step == 0], color=\"green\",label=\"Accurce_train\")\n","\n","  ax2.legend(loc=\"best\")\n","  ax2.set_xlabel('Chunk')\n","  ax2.set_ylabel('Results per Chunk')\n","\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),title))\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),title+'.svg'),format='svg')\n","  plt.show()"]},{"cell_type":"code","source":["def selected_features_for_each_cluster(tabu,number_of_chunk):\n","  # set width of bar\n","  barWidth = 0.05\n","  fig = plt.subplots(figsize =(15, 5))\n","  # Set position of bar on X axis\n","  br1 = np.arange(len(tabu))\n","  # Make the plot\n","  plt.bar(br1, tabu,label ='2TS-DFS') # tabu\n","  # Adding Xticks\n","  plt.xlabel('cluster number', fontweight ='bold', fontsize = 10)\n","  plt.ylabel('The remaining dimensions after being reduced from 100', fontweight ='bold', fontsize = 8)\n","  plt.xticks([r + barWidth for r in range(len(tabu))],[str(i) for i,_ in enumerate(tabu)])\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"selected features for each cluster in chunk_\"+str(number_of_chunk)))\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"selected features for each cluster in chunk_\"+str(number_of_chunk)+\".svg\"),format='svg')\n","  plt.show()"],"metadata":{"id":"n5lGApBTHKvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _plot_results_for_chunk_number(chunk_number,f1=None,ac=None,pr=None,rc=None,step=None):\n","\n","    plt.figure(figsize=(15, 5))\n","\n","    if step is None:\n","      number = f1.index(max(f1)) if type(f1) is list else list(f1).index(max(f1))\n","      factors = find_factors(number) if number!=0 else [3,5]\n","      step = factors[1] if len(factors)==2 else factors[2]\n","\n","    plt.title(\"Tabu Search results for chunk number \"+str(chunk_number))\n","    XF = [x for i, x in enumerate(f1) if i % step == 0]\n","    XA = [x for i, x in enumerate(ac) if i % step == 0]\n","    XFT = [x for i, x in enumerate(pr) if i % step == 0]\n","    XAT = [x for i, x in enumerate(rc) if i % step == 0]\n","    save_object(XF, \"F1_Score_test_\"+str(chunk_number),results_path)\n","    save_object(XA, \"Accurce_score_test_\"+str(chunk_number),results_path)\n","    save_object(XFT, \"F1_Score_train_\"+str(chunk_number),results_path)\n","    save_object(XAT, \"Accurce_score_train_\"+str(chunk_number),results_path)\n","\n","    plt.plot([i for i, x in enumerate(f1) if i % step == 0],XF, color=\"red\",label=\"F1_Score_test\")\n","    plt.plot([i for i, x in enumerate(ac) if i % step == 0],XA, color=\"blue\",label=\"Accurce_score_test\")\n","    plt.plot([i for i, x in enumerate(pr) if i % step == 0],XFT, color=\"yellow\",label=\"F1_Score_train\")\n","    plt.plot([i for i, x in enumerate(rc) if i % step == 0],XAT, color=\"green\",label=\"Accurce_score_train\")\n","\n","    plt.scatter(f1.index(max(f1)) if type(f1) is list else list(f1).index(max(f1)), max(f1), color='orange', s=25)\n","\n","    plt.vlines(x=f1.index(max(f1)) if type(f1) is list else list(f1).index(max(f1)), ymin=min([min(f1),min(f1),min(f1),min(f1)]),\n","               ymax=max([max(f1),max(ac),max(pr),max(rc)]), colors='black', lw=1)\n","\n","    plt.hlines(y=max(f1), xmin=0,\n","            xmax=f1.index(max(f1)) if type(f1) is list else list(f1).index(max(f1)), colors='black', lw=1)\n","\n","    plt.legend(loc=\"best\")\n","    plt.xlabel('iteration')\n","    plt.ylabel('results per iteration')\n","    # plt.xscale('log',base=2)\n","\n","    # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Tabu Search results for chunk number \"+str(chunk_number)))\n","    # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Tabu Search results for chunk number \"+str(chunk_number)+'.svg'),format='svg')\n","    plt.show()"],"metadata":{"id":"3z53OrUrPsmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_results_for_chunk_number(chunk_number,f1=None,ac=None,pr=None,rc=None,step=5):\n","\n","    plt.figure(figsize=(15, 5))\n","\n","    plt.title(\"Tabu Search results for chunk number \"+str(chunk_number))\n","    plt.plot([i for i, x in enumerate(f1) if i % step == 0],[x for i, x in enumerate(f1) if i % step == 0], color=\"red\",label=\"F1_Score\")\n","    plt.plot([i for i, x in enumerate(ac) if i % step == 0],[x for i, x in enumerate(ac) if i % step == 0], color=\"blue\",label=\"Accurce_score\")\n","    plt.plot([i for i, x in enumerate(pr) if i % step == 0],[x for i, x in enumerate(pr) if i % step == 0], color=\"yellow\",label=\"Precision_score\")\n","    plt.plot([i for i, x in enumerate(rc) if i % step == 0],[x for i, x in enumerate(rc) if i % step == 0], color=\"green\",label=\"Recall_score\")\n","\n","    plt.legend(loc=\"best\")\n","    plt.xlabel('iteration')\n","    plt.ylabel('results per iteration')\n","    plt.xscale('log',base=2)\n","\n","    # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Tabu_Search_results_for_chunk_number_\"+str(chunk_number)))\n","    # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Tabu_Search_results_for_chunk_number_\"+str(chunk_number)+'.svg'),format='svg')\n","    plt.show()"],"metadata":{"id":"gG0f1DYPHXdU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"516QleFtvwPa"},"outputs":[],"source":["import matplotlib.ticker as mticker\n","\n","def plot_results(metric_name, methods_name, colors, step=1):\n","    results = finder(metric_name)\n","    plt.figure(figsize=(15, 5))\n","    plt.title(metric_name)\n","    for k, result in enumerate(results):\n","        x = [i for i, x in enumerate(results[k]) if i % step == 0]\n","        y = [x for i, x in enumerate(results[k]) if i % step == 0]\n","        plt.plot(x, y, color=colors[k], label=methods_name[k])\n","        plt.scatter(x, y, color=colors[k], s=20)  # Add dots to the plot\n","\n","    plt.legend(loc=\"best\")\n","    plt.xlabel('Chunk number')\n","    plt.ylabel('Results per Chunk')\n","\n","    # Format x-axis ticks as integers\n","    plt.xticks(rotation=90)\n","    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(step))\n","    plt.gca().xaxis.set_major_formatter(plt.ScalarFormatter(useOffset=False, useMathText=True))\n","\n","    # plt.savefig(os.path.join(os.path.join(results_path, 'Imges'), metric_name))\n","    # plt.savefig(os.path.join(os.path.join(results_path, 'Imges'), metric_name+'.svg'), format='svg')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srP6IXf0J1-J"},"outputs":[],"source":["def plot_dimensional_reduction(tabu,softmax,single_agent,average):\n","  # set width of bar\n","  barWidth = 0.05\n","  fig = plt.subplots(figsize =(8, 5))\n","  # Set position of bar on X axis\n","  br1 = np.arange(len(tabu))\n","  br2 = [x + barWidth for x in br1]\n","  br3 = [x + barWidth for x in br2]\n","  br4 = [x + barWidth for x in br3]\n","  # Make the plot\n","\n","  plt.bar(br1, tabu, color ='r', width = barWidth,edgecolor ='grey', label ='2TS-DFS')\n","  plt.bar(br2, softmax, color ='g', width = barWidth,edgecolor ='grey', label ='ALC')\n","  plt.bar(br3, single_agent, color ='b', width = barWidth,edgecolor ='grey', label ='OA-OT')\n","  plt.bar(br4, average, color ='y', width = barWidth,edgecolor ='grey', label ='AC')\n","  # Adding Xticks\n","  plt.xlabel('Chunk number', fontweight ='bold', fontsize = 10)\n","  plt.ylabel('The remaining dimensions after being reduced from 100', fontweight ='bold', fontsize = 8)\n","  plt.xticks([r + barWidth for r in range(len(number_of_chunk))],[str(i) for i,_ in enumerate(number_of_chunk)])\n","  plt.legend(loc=\"best\")\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Dimensional reduction amount\"))\n","  # plt.savefig(os.path.join(os.path.join(results_path,'Imges'),\"Dimensional reduction amount.svg\"),format='svg')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PubRcDB0k3I"},"outputs":[],"source":["def PointsInCircum(r,n=100):\n","    return [(math.cos(2*math.pi/n*x)*r+np.random.normal(-30,30),math.sin(2*math.pi/n*x)*r+np.random.normal(-30,30)) for x in range(1,n+1)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxlMIyXuKm1Q"},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score,ConfusionMatrixDisplay\n","from sklearn.metrics import roc_curve, auc\n","import pandas as pd\n","\n","def plot_conf_matrix(true, pred, classes):\n","    cf = confusion_matrix(true, pred)\n","    plt.figure(figsize=(12,10))\n","    sns.set(font_scale=1.4)\n","    sns.heatmap(np.round(cf / cf.sum(axis=0), 3).T, annot=True, annot_kws={\"size\": 16},fmt='g',\n","                cmap='Blues', xticklabels = classes ,yticklabels = classes)\n","    # plt.savefig('confusion_matrix.png')\n","    # plt.savefig('confusion_matrix.svg')\n","\n","    plt.show()\n","# plot_conf_matrix(labels, y_preds, class_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9NYJ6gj5L90"},"outputs":[],"source":["def get_callbacks():\n","  filepath = os.path.join(model_info_path,'Tabu_Search_'+str(num)+'_.best.hdf5')\n","  history_logger = CSVLogger(os.path.join(model_info_path,'history'+str(num)+'.csv'), separator=\",\", append=True)\n","  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n","  es = EarlyStopping(monitor='val_loss', patience=5)\n","  callbacks_list = [GarbageCollectorCallback(),es,history_logger,checkpoint] # ,,\n","  return callbacks_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FT0ODMi7GVDC"},"outputs":[],"source":["def evaluate_result(y_predict,y_true):\n","    y_predict[y_predict>0.5] = 1\n","    y_true = list(map(_replaceitem, y_true))\n","    y_predict = list(map(_replaceitem, y_predict))\n","    return f1_score(y_true=y_true,y_pred=y_predict),accuracy_score(y_true=y_true,y_pred=y_predict),precision_score(y_true=y_true,y_pred=y_predict),recall_score(y_true=y_true,y_pred=y_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqGeTzVaGVDD"},"outputs":[],"source":["def chunking_data(NUMBER):\n","    \"\"\"\n","    _INPUT (Data) CHUNK OF DATASET (test_size=0.20) SIZE OF SPLITNG\n","    _OUTPUT (X_train , y_train , X_test , y_test)\n","    \"\"\"\n","    x_chunk , y_chunk = load_object('X_train_hiden_for_chunk_'+str(NUMBER),par_path) , load_object('y_train_hiden_for_chunk_'+str(NUMBER),par_path)\n","    X_new_chunks , y_new_chunks = np.array(np.split(x_chunk, x_chunk.shape[0]/100)) , np.array(np.split(y_chunk, y_chunk.shape[0]/100))\n","    return X_new_chunks[:-1] , y_new_chunks[:-1] , X_new_chunks[-1] , y_new_chunks[-1]"]},{"cell_type":"code","source":["def finder(metric):\n","  result = pd.read_csv(os.path.join(os.path.join(results_path,'Imges'),\"Numerical results.csv\"))\n","  return  [result[result['Method_name']=='2TS-DFS'][metric].tolist(),\n","          result[result['Method_name']=='ALC'][metric].tolist(),\n","          result[result['Method_name']=='OA-OT'][metric].tolist(),\n","          result[result['Method_name']=='AC'][metric].tolist(),\n","          result[result['Method_name']=='JSContana-S'][metric].tolist(),\n","          result[result['Method_name']=='JSContana'][metric].tolist()]"],"metadata":{"id":"kSzRZanCYGlo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y55YrCS8UysW"},"outputs":[],"source":["def apply_change_on_data(X,mask,change):\n","  if change[0] is None:\n","    return apply_mask(X,mask),mask\n","  mask[change[0]][change[1]] = 1-mask[change[0]][change[1]]\n","  return apply_mask(X.copy(),mask.copy()),mask.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSU9kYrDqW6x"},"outputs":[],"source":["def check_aspiration_criteria(f1,ac):\n","  f1_aspiration_criteria,ac_aspiration_criteria= 0.80,0.80\n","  if(f1>=f1_aspiration_criteria)and(ac>=ac_aspiration_criteria):return True\n","  else:return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBXYI8PCKVwQ"},"outputs":[],"source":["def get_similarity(X_test,X_train):\n","  similarites=[]\n","  for x in X_test:\n","    similarity=[]\n","    for X in X_train:\n","      similarity.append(np.mean(np.sum(x*X, axis=1)/(norm(x, axis=1)*norm(X, axis=1))))\n","    similarites.append(similarity.index(max(similarity)))\n","  return similarites"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDFxaFPdEmyU"},"outputs":[],"source":["def get_euclidean_distance(X_test,X_train,cluster_train):\n","  distances = []\n","  for x_test in X_test:\n","    distanc = []\n","    for x_train in X_train:\n","      distanc.append(np.sum(np.square(x_test - x_train)))\n","    distances.append(distanc.index(min(distanc)))\n","  return cluster_train[distances]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lcgb1h84cc6"},"outputs":[],"source":["def update_tabu_list(solution):\n","  Tabu_list.append(solution)\n","  value_of_update = len(Tabu_list)-Tabu_tenur\n","  if value_of_update>0:\n","    del Tabu_list[:value_of_update]\n","  return Tabu_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gh7lAhFiMkS6"},"outputs":[],"source":["def apply_mask(X,mask,cluster=None):\n","  if cluster is None:\n","    for i,x in enumerate(X):\n","      X[i] = x*mask\n","  else:\n","    for i,x in enumerate(X):\n","      X[i] = x*mask[cluster[i]]\n","  return X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UU2AfUSREY3X"},"outputs":[],"source":["def get_statistical_information(X):\n","  new_x = []\n","  for x in X:\n","    new_x.append(np.array([np.ndarray.min(x),np.ndarray.max(x),np.ndarray.mean(x),np.ndarray.std(x),np.median(x),np.var(x)]))\n","  return np.array(new_x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wTJQwMAjtfsf"},"outputs":[],"source":["def save(i):\n","  save_object(solutions, 'solutions_'+str(i),results_path)\n","  save_object(Precision_test, 'Precision_test_'+str(i),results_path)\n","  save_object(Recall_test, 'Recall_test_'+str(i),results_path)\n","  save_object(F1_test, 'F1_test_'+str(i),results_path)\n","  save_object(Ac_test, 'Ac_test_'+str(i),results_path)\n","  save_object(Tabu_list, 'Tabu_list_'+str(i),results_path)\n","  save_object(cluster_train, 'cluster_train_'+str(i),results_path)\n","  save_object(cluster_test, 'cluster_test_'+str(i),results_path)\n","  save_object(F1_train, 'F1_train_'+str(i),results_path)\n","  save_object(Ac_train, 'Ac_train_'+str(i),results_path)\n","  save_object(Precision_test, 'Precision_train_'+str(i),results_path)\n","  save_object(Recall_test, 'Recall_train_'+str(i),results_path)\n","  save_object(agglomerativeClustering, 'agglomerativeClustering_'+str(i),results_path)\n","  save_object(y_test_predict, 'y_test_predict'+str(i),results_path)\n","  save_object(y_train_predict, 'y_train_predict'+str(i),results_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZHJvhYw1RVP"},"outputs":[],"source":["def load(i):\n","  F1_train = load_object('Precision_test_'+str(i),results_path)\n","  F1_test = load_object('F1_test_'+str(i),results_path)\n","  Ac_train = load_object('Recall_test_'+str(i),results_path)\n","  Ac_test = load_object('Ac_test_'+str(i),results_path)\n","  return F1_test,Ac_test,Recall_test,Precision_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PX8q6ZJ_7CXq"},"outputs":[],"source":["def neighbour_solution(solution,e=False):\n","  if e:\n","    new_solution = np.random.randint(low=0,high=2,size=(number_of_calss,X_train.shape[2]))\n","  else:\n","    new_solution = solution.copy()\n","    for i,_ in enumerate(new_solution):\n","      neighbours = np.random.randint(low=0,high=100,size=5)\n","      for j in neighbours:\n","        new_solution[i][j] = 1-solution[i][j]\n","  return new_solution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7otkZH7c7jBy"},"outputs":[],"source":["def Tabu_list_checker(solution):\n","  for t in Tabu_list:\n","    if np.all(np.equal(solution,t)):\n","      return True\n","  return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2U_wJk2Rstx"},"outputs":[],"source":["def generate_neighbour_solution(solution,e=False):\n","  neighbour = neighbour_solution(solution,e)\n","  while True:\n","    t = Tabu_list_checker(neighbour)\n","    if t:neighbour = neighbour_solution(solution,e)\n","    else:break\n","  return neighbour"]},{"cell_type":"markdown","metadata":{"id":"LXSEJKhVBc03"},"source":["## Tabu Search Algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yj3Q2RPWABW5"},"outputs":[],"source":["number_of_calss = 35\n","Tabu_tenur,Tabu_list,num=100,[],0\n","number_of_chunk =[i[:-4] for i in os.listdir(par_path)[::-1] if i[:7]=='X_train']\n","number_of_chunk = number_of_chunk[:-1]\n","agglomerativeClustering = AgglomerativeClustering(n_clusters=number_of_calss, affinity='euclidean')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6pKujBORAvJ9"},"outputs":[],"source":["for i,x in tqdm(enumerate(number_of_chunk)):\n","  X_train , y_train = load_object('X_train_hiden_for_chunk_'+str(i),par_path) , load_object('y_train_hiden_for_chunk_'+str(i),par_path)\n","  X_test , y_test = load_object('X_test_hiden_for_chunk_'+str(i),par_path) , load_object('y_test_hiden_for_chunk_'+str(i),par_path)\n","  number_of_iteration,num = X_train.shape[2]*10,i\n","  if i==0:\n","    model = create_model(shape=X_train[0].shape,without_first_layer=True,i=i)\n","    model.save(os.path.join(model_info_path,\"tabu_search_model.h5\"))\n","  else:\n","    Tabu_list = load_object('Tabu_list_'+str(i-1),results_path)\n","    agglomerativeClustering = load_object('agglomerativeClustering',results_path)\n","    model = load_model(os.path.join(model_info_path,\"tabu_search_model.h5\"))\n","  cluster_train = agglomerativeClustering.fit_predict(get_statistical_information(X_train))\n","  cluster_test = get_euclidean_distance(X_test,X_train,cluster_train)\n","  current_solution = np.random.randint(low=0,high=2,size=(number_of_calss,X_train.shape[2]))\n","  solutions,F1_train,Ac_train,F1_test,Ac_test,Precision_test,Recall_test,Precision_train,Recall_train = [],[],[],[],[],[],[],[],[]\n","  for step in tqdm(range(number_of_iteration)):\n","    x_train = X_train.copy()\n","    x_train = apply_mask(x_train,current_solution,cluster_train)\n","    history = model.fit(x_train, y_train,epochs=10,batch_size=100,validation_split=0.20,callbacks=get_callbacks(), verbose=0)\n","    x_test = X_test.copy()\n","    x_test = apply_mask(x_test,current_solution,cluster_test)\n","    y_test_predict = model.predict(x_test, verbose=0)\n","    f1_test,ac_test,precision_test,recall_test =  evaluate_result(y_test_predict,y_test)\n","    y_train_predict = model.predict(x_train, verbose=0)\n","    f1_train,ac_train,precision_train,recall_tain =  evaluate_result(y_train_predict,y_train)\n","\n","    Tabu_list = update_tabu_list(current_solution)\n","    aspiration_criteria = check_aspiration_criteria(f1_test,ac_test)\n","    if not aspiration_criteria:\n","      del model\n","      model = load_model(os.path.join(model_info_path,\"tabu_search_model.h5\"))\n","    else:\n","      model.save(os.path.join(model_info_path,\"tabu_search_model.h5\"))\n","\n","    solutions.append(current_solution)\n","    Precision_test.append(precision_test)\n","    F1_test.append(f1_test)\n","    Recall_test.append(recall_test)\n","    Ac_test.append(ac_test)\n","\n","    Precision_train.append(precision_train)\n","    F1_train.append(f1_train)\n","    Recall_train.append(recall_tain)\n","    Ac_train.append(ac_train)\n","\n","    save(i)\n","    e = True if max(F1_test)<97 else False\n","    current_solution = generate_neighbour_solution(current_solution.copy(),e)\n","    if f1_test>=97:break"]},{"cell_type":"code","source":[],"metadata":{"id":"kG6h0kq5dp0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lrn4MTUQLOE3"},"outputs":[],"source":["for i in range(len(number_of_chunk)):\n","  solution = load_object('best_solution__'+str(i),results_path)\n","  sums = []\n","  for s in solution:\n","    sums.append(sum(s))\n","  selected_features_for_each_cluster(sums,i)"]},{"cell_type":"code","source":["_tabu = load_object('_tabu',results_path)\n","_softmax = load_object('_softmax',results_path)\n","_single_agent = load_object('_single_agent',results_path)\n","_average = load_object('_average',results_path)\n","plot_dimensional_reduction(_tabu,_softmax,_single_agent,_average)"],"metadata":{"id":"xe9wYgbaHree"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["methods_name = ['2TS-DFS','ALC','OA-OT','AC','JSContana-S','JSContana']\n","colors = ['r', 'g', 'b', 'm', 'c','y']"],"metadata":{"id":"VP2ECGIuYBWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Accuracy_score',methods_name,colors,step=1)"],"metadata":{"id":"rZG7xr2KOmM9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Precision_score',methods_name,colors,step=1)"],"metadata":{"id":"ejHjd8VqOtj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Recall_score',methods_name,colors,step=1)"],"metadata":{"id":"VKGQhYHLOto5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('F1_score',methods_name,colors,step=1)"],"metadata":{"id":"ClZXyoJoOtvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Prediction_Time',methods_name,colors,step=1)"],"metadata":{"id":"La_dsY-OOtz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Binary Cross-Entropy',methods_name,colors,step=1)"],"metadata":{"id":"EhLoh7kwNUUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Mean Absolute Error',methods_name,colors,step=1)"],"metadata":{"id":"Xt0I6xReOqes"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('Mean Squared Error',methods_name,colors,step=1)"],"metadata":{"id":"h7Rqa7NTOqi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_results('False Positive Rate',methods_name,colors,step=1)"],"metadata":{"id":"YDnM-iMIOz5X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loader(i):\n","  F1_train = load_object('_F1_train'+str(i),results_path)\n","  F1_test = load_object('_F1_test'+str(i),results_path)\n","  Ac_train = load_object('_Ac_train'+str(i),results_path)\n","  Ac_test = load_object('_Ac_test'+str(i),results_path)\n","  return F1_train,F1_test,Ac_train,Ac_test"],"metadata":{"id":"Gy6lHF7RPhGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_factors(number):\n","    factors = []\n","    for i in range(1, number + 1):\n","        if number % i == 0:\n","            factors.append(i)\n","    return factors"],"metadata":{"id":"WE4JA_6NP8ej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(4):\n","  F1_train,F1_test,Ac_train,Ac_test = loader(i)\n","  _plot_results_for_chunk_number(i,f1=F1_test,ac=Ac_test,pr=F1_train,rc=Ac_train)"],"metadata":{"id":"7B2yK4w-PPCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8YebOhL6PWqO"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}